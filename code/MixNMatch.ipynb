{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "MixNMatch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVnsXjjLOZYu",
        "outputId": "f9676f23-2053-4cef-ad45-b611a73d2d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBCF6YZ_0WSz"
      },
      "source": [
        "# First train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1KHo7UxzvvF"
      },
      "source": [
        "from config import cfg\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "from model_train import G_NET, BACKGROUND_D, PARENT_D, CHILD_D, Encoder, Bi_Dis\n",
        "from datasets import get_dataloader\n",
        "import random\n",
        "from utils import *\n",
        "from itertools import chain\n",
        "from copy import deepcopy\n",
        "import csv\n",
        "cudnn.benchmark = True\n",
        "device = torch.device(\"cuda:\" + cfg.GPU_ID)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################### Useful functions ###################\n",
        "\n",
        "\n",
        "\n",
        "def define_optimizers( netG, netsD, BD, encoder ):\n",
        "\n",
        "    # define optimizer for D\n",
        "    optimizersD = []  \n",
        "    for i in range(3):\n",
        "        if i == 0 or i==2:\n",
        "            optimizersD.append( optim.Adam(netsD[i].parameters(), lr=2e-4, betas=(0.5, 0.999)) )   \n",
        "        else:\n",
        "            optimizersD.append(None)\n",
        "  \n",
        "    optimizerBD = optim.Adam( BD.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "  \n",
        "    params = chain( netG.parameters(), encoder.parameters(), netsD[1].parameters(), netsD[2].module.code_logits.parameters() )       \n",
        "    optimizerGE = optim.Adam(  params , lr=2e-4, betas=(0.5, 0.999) ) \n",
        " \n",
        "   \n",
        "    return optimizersD, optimizerBD, optimizerGE\n",
        "\n",
        "\n",
        "\n",
        "def load_params(model, new_param):\n",
        "    for p, new_p in zip(model.parameters(), new_param):\n",
        "        p.data.copy_(new_p)\n",
        "\n",
        "\n",
        "def copy_G_params(model):\n",
        "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten\n",
        "\n",
        "\n",
        "class CrossEntropy():\n",
        "    def __init__(self):\n",
        "        self.code_loss = nn.CrossEntropyLoss() \n",
        "    def __call__(self, prediction, label):\n",
        "        # check label if hard (onehot)\n",
        "        if label.max(dim=1)[0].min() == 1:\n",
        "            return self.code_loss(prediction, torch.nonzero( label.long() )[:, 1] )\n",
        "        else:        \n",
        "            log_prediction = torch.log_softmax(prediction, dim=1)    \n",
        "            return (- log_prediction*label).sum(dim=1).mean(dim=0)\n",
        "\n",
        "\n",
        "\n",
        "def load_network():\n",
        "\n",
        "    gpus = [int(ix) for ix in cfg.GPU_ID.split(',')]\n",
        " \n",
        "    netG = G_NET()\n",
        "    netG.apply(weights_init)\n",
        "    netG = torch.nn.DataParallel(netG, device_ids=gpus)\n",
        "  \n",
        "    netsD = [ BACKGROUND_D(), PARENT_D(), CHILD_D() ]\n",
        "    for i in range(len(netsD)):\n",
        "        netsD[i].apply(weights_init)\n",
        "        netsD[i] = torch.nn.DataParallel(netsD[i], device_ids=gpus)       \n",
        "\n",
        "    BD = Bi_Dis()\n",
        "    BD = torch.nn.DataParallel(BD, device_ids=gpus)     \n",
        "\n",
        "    encoder = Encoder()\n",
        "    encoder.apply(weights_init)\n",
        "    encoder = torch.nn.DataParallel(encoder, device_ids=gpus)\n",
        "   \n",
        "    netG.to(device)  \n",
        "    encoder.to(device)  \n",
        "    BD.to(device)\n",
        "    for i in range(3):\n",
        "        netsD[i].to(device)\n",
        "\n",
        "    return netG, netsD, BD, encoder\n",
        "\n",
        "def load_network_from_file():\n",
        "    #\"load pretrained generator and encoder\"\n",
        "\n",
        "    names = [ os.path.join(cfg.MODELS_DIR,'G.pth'), os.path.join(cfg.MODELS_DIR,'E.pth')  ]\n",
        "    gpus = [int(ix) for ix in cfg.GPU_ID.split(',')]\n",
        "    \n",
        "    # prepare G net     \n",
        "    netG = G_NET().to(device)  #?\n",
        "    netG = torch.nn.DataParallel(netG, device_ids=gpus)\n",
        "    state_dict = torch.load( names[0]  )\n",
        "    netG.load_state_dict(state_dict)\n",
        "\n",
        "    # prepare encoder\n",
        "    encoder = Encoder().to(device)\n",
        "    #print(\"encode is \", encoder)\n",
        "    encoder = torch.nn.DataParallel(encoder, device_ids=gpus)\n",
        "    state_dict = torch.load( names[1] )\n",
        "    encoder.load_state_dict(state_dict)\n",
        "    \n",
        "    other_names = [ os.path.join(cfg.MODELS_DIR,'D0.pth'), os.path.join(cfg.MODELS_DIR,'D1.pth'),\n",
        "                    os.path.join(cfg.MODELS_DIR,'D2.pth'), os.path.join(cfg.MODELS_DIR,'BD.pth')  ]\n",
        "\n",
        "    netsD = [ BACKGROUND_D(), PARENT_D(), CHILD_D() ]\n",
        "    for i in range(len(netsD)):\n",
        "        #netsD[i].apply(weights_init)\n",
        "        netsD[i] = torch.nn.DataParallel(netsD[i], device_ids=gpus)\n",
        "        state_dict = torch.load( other_names[i]  )\n",
        "        netsD[i].load_state_dict(state_dict)       \n",
        "\n",
        "    BD = Bi_Dis()\n",
        "    BD = torch.nn.DataParallel(BD, device_ids=gpus)\n",
        "    state_dict = torch.load( other_names[3]  )\n",
        "    BD.load_state_dict(state_dict)      \n",
        " \n",
        "    BD.to(device)\n",
        "    for i in range(3):\n",
        "        netsD[i].to(device)\n",
        "\n",
        "\n",
        "    #return netG.eval(), encoder.eval()\n",
        "    return netG, netsD, BD, encoder\n",
        "\n",
        "\n",
        "def save_model( encoder, myG, D0, D1, D2, BD, epoch, model_dir):\n",
        "    torch.save(encoder.state_dict(), '%s/E_%d.pth' % (model_dir, epoch))\n",
        "    torch.save(myG.state_dict(), '%s/G_%d.pth' % (model_dir, epoch))\n",
        "    torch.save(D0.state_dict(), '%s/D0_%d.pth' % (model_dir, epoch))\n",
        "    torch.save(D1.state_dict(), '%s/D1_%d.pth' % (model_dir, epoch))\n",
        "    torch.save(D2.state_dict(), '%s/D2_%d.pth' % (model_dir, epoch))\n",
        "    torch.save(BD.state_dict(), '%s/BD_%d.pth' % (model_dir, epoch))\n",
        "\n",
        "\n",
        "\n",
        "def save_opt( optimizerGE,  optimizerD0,  optimizerD2, optimizerBD, epoch, opt_dir):\n",
        "    torch.save(optimizerGE.state_dict(), '%s/GE_%d.pth' % (opt_dir, epoch))\n",
        "    torch.save(optimizerD0.state_dict(), '%s/D0_%d.pth' % (opt_dir, epoch))\n",
        "    torch.save(optimizerD2.state_dict(), '%s/D2_%d.pth' % (opt_dir, epoch))\n",
        "    torch.save(optimizerBD.state_dict(), '%s/BD_%d.pth' % (opt_dir, epoch))\n",
        "\n",
        "    \n",
        "def log_loss(output_csv_file, eg_loss_dict,epoch):\n",
        "    with open(output_csv_file, 'a') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=[\"z_pred_loss\", \"b_pred_loss\", \"p_pred_loss\",\n",
        "                                                    \"c_pred_loss\", \"bg_rf_loss\", \"bg_class_loss\",\n",
        "                                                    \"child_rf_loss\", \"fool_BD_loss\", \"EG_loss\",\n",
        "                                                    \"d0_loss\", \"d2_loss\", \"bd_loss\", \"epoch\", \"data_number\"])\n",
        "        if(epoch == 0):\n",
        "            writer.writeheader()\n",
        "        \n",
        "        writer.writerow(eg_loss_dict)\n",
        "\n",
        "############################### Trainer ############################\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self, output_dir):\n",
        "\n",
        "        # make dir for all kinds of output \n",
        "        self.model_dir = os.path.join(output_dir , 'Model')\n",
        "        os.makedirs(self.model_dir)\n",
        "        self.image_dir = os.path.join(output_dir , 'Image')\n",
        "        os.makedirs(self.image_dir)\n",
        "        self.opt_dir = os.path.join(output_dir , 'Opt')\n",
        "        os.makedirs(self.opt_dir)\n",
        "        self.output_csv_file = os.path.join(output_dir , 'losses.csv')\n",
        "\n",
        "        # make dataloader and code buffer \n",
        "        self.dataloader = get_dataloader()\n",
        "      \n",
        "        # other variables\n",
        "        self.batch_size = cfg.TRAIN.BATCH_SIZE \n",
        "        self.patch_stride = 4.0 \n",
        "        self.n_out = 24\n",
        "        self.recp_field = 34       \n",
        "\n",
        "        # get fixed images used for comparison for each epoch \n",
        "        self.fixed_image =  self.prepare_data(  next(iter(self.dataloader)) )[1]\n",
        "        save_img_results( self.fixed_image.cpu(), None, -1, self.image_dir )\n",
        "\n",
        " \n",
        "    def prepare_code(self):\n",
        "\n",
        "        free_z = torch.FloatTensor( self.batch_size, cfg.GAN.Z_DIM ).normal_(0, 1).to(device)\n",
        "\n",
        "        free_c = torch.zeros( self.batch_size, cfg.FINE_GRAINED_CATEGORIES ).to(device)\n",
        "        idxs = torch.LongTensor( self.batch_size ).random_(0, cfg.FINE_GRAINED_CATEGORIES)\n",
        "        for i, idx in enumerate(idxs):\n",
        "            free_c[i,idx] = 1\n",
        "        free_p = torch.zeros( self.batch_size, cfg.SUPER_CATEGORIES ).to(device)\n",
        "        idxs = torch.LongTensor( self.batch_size ).random_(0, cfg.SUPER_CATEGORIES)\n",
        "        for i, idx in enumerate(idxs):\n",
        "            free_p[i,idx] = 1\n",
        "        free_b = torch.zeros( self.batch_size, cfg.FINE_GRAINED_CATEGORIES ).to(device)\n",
        "        idxs = torch.LongTensor( self.batch_size ).random_( 0, cfg.FINE_GRAINED_CATEGORIES )\n",
        "        for i, idx in enumerate(idxs):\n",
        "            free_b[i,idx] = 1\n",
        "\n",
        "        return free_z, free_b, free_p, free_c\n",
        "\n",
        "    \n",
        "\n",
        "    def prepare_data(self, data):\n",
        "\n",
        "        real_img126, real_img, real_c, _, warped_bbox = data \n",
        "        real_img126 = real_img126.to(device)\n",
        "        real_img = real_img.to(device)\n",
        "        for i in range(len(warped_bbox)):\n",
        "            warped_bbox[i] = warped_bbox[i].float().to(device)\n",
        "\n",
        "        real_p = child_to_parent(real_c, cfg.FINE_GRAINED_CATEGORIES, cfg.SUPER_CATEGORIES ).to(device)\n",
        "        real_z = torch.FloatTensor( self.batch_size, cfg.GAN.Z_DIM ).normal_(0, 1).to(device) \n",
        "        real_c = real_c.to(device)\n",
        "        real_b = real_c             \n",
        "\n",
        "        return  real_img126, real_img, real_z, real_b, real_p, real_c, warped_bbox\n",
        "\n",
        "\n",
        "    def train_Dnet(self, idx):\n",
        "\n",
        "        assert(idx == 0 or idx ==2)\n",
        "  \n",
        "        # choose net and opt  \n",
        "        netD, optD = self.netsD[idx], self.optimizersD[idx]\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # choose real and fake images\n",
        "        if idx == 0:\n",
        "            real_img = self.real_img126\n",
        "            fake_img = self.fake_imgs[0]\n",
        "        elif idx == 2:\n",
        "            real_img = self.real_img\n",
        "            fake_img = self.fake_imgs[2]   \n",
        "\n",
        "        # # # # # # # #for background stage now  # # # # # # #\n",
        "        if idx == 0:\n",
        "\n",
        "            # go throung D net to get prediction\n",
        "            class_prediction, real_prediction = netD(real_img) \n",
        "            _, fake_prediction = netD( fake_img.detach() )   \n",
        "\n",
        "            real_label = torch.ones_like(real_prediction)\n",
        "            fake_label = torch.zeros_like(fake_prediction)     \n",
        "            weights_real = torch.ones_like(real_prediction)\n",
        "            \n",
        "            for i in range( self.batch_size ):\n",
        "\n",
        "                x1 = self.warped_bbox[0][i]\n",
        "                x2 = self.warped_bbox[2][i]\n",
        "                y1 = self.warped_bbox[1][i]\n",
        "                y2 = self.warped_bbox[3][i]\n",
        "\n",
        "                a1 = max(torch.tensor(0).float().to(device), torch.ceil((x1 - self.recp_field)/self.patch_stride))\n",
        "                a2 = min(torch.tensor(self.n_out - 1).float().to(device), torch.floor((self.n_out - 1) - ((126 - self.recp_field) - x2)/self.patch_stride)) + 1\n",
        "                b1 = max(torch.tensor(0).float().to(device), torch.ceil( (y1 - self.recp_field)/self.patch_stride))\n",
        "                b2 = min(torch.tensor(self.n_out - 1).float().to(device), torch.floor((self.n_out - 1) - ((126 - self.recp_field) - y2)/self.patch_stride)) + 1\n",
        "\n",
        "                if (x1 != x2 and y1 != y2):\n",
        "                    weights_real[i, :, a1.type(torch.int): a2.type(torch.int), b1.type(torch.int): b2.type(torch.int)] = 0.0\n",
        "\n",
        "            norm_fact_real = weights_real.sum()\n",
        "            norm_fact_fake = weights_real.shape[0]*weights_real.shape[1]*weights_real.shape[2]*weights_real.shape[3]\n",
        "\n",
        "            # Real/Fake loss for 'real background' (on patch level)\n",
        "            real_prediction_loss = self.RF_loss_un( real_prediction, real_label )\n",
        "            # Masking output units which correspond to receptive fields which lie within the bounding box\n",
        "            real_prediction_loss = torch.mul(real_prediction_loss, weights_real).mean()\n",
        "            # Normalizing the real/fake loss for background after accounting the number of masked members in the output.\n",
        "            if (norm_fact_real > 0):\n",
        "                real_prediction_loss = real_prediction_loss * ((norm_fact_fake * 1.0) / (norm_fact_real * 1.0))\n",
        "\n",
        "            # Real/Fake loss for 'fake background' (on patch level)\n",
        "            fake_prediction_loss = self.RF_loss_un(fake_prediction, fake_label).mean()        \n",
        "          \n",
        "            # Background/foreground classification loss\n",
        "            class_prediction_loss = self.RF_loss_un( class_prediction, weights_real ).mean()  \n",
        "\n",
        "            # add three losses together \n",
        "            D_loss = cfg.TRAIN.BG_LOSS_WT*(real_prediction_loss + fake_prediction_loss) + class_prediction_loss\n",
        "      \n",
        "\n",
        "        # # # # # # # #for child stage now (only real/fake discriminator)  # # # # # # # \n",
        "        if idx == 2:\n",
        "\n",
        "            # go through D net to get data\n",
        "            _, real_prediction = netD(real_img) \n",
        "            _, fake_prediction = netD( fake_img.detach() )\n",
        "\n",
        "            # get real/fake lables\n",
        "            real_label = torch.ones_like(real_prediction)\n",
        "            fake_label = torch.zeros_like(fake_prediction) \n",
        " \n",
        "            # get loss \n",
        "            real_prediction_loss = self.RF_loss(real_prediction, real_label)         \n",
        "            fake_prediction_loss = self.RF_loss(fake_prediction, fake_label)\n",
        "            D_loss = real_prediction_loss+fake_prediction_loss\n",
        "\n",
        "        D_loss.backward()\n",
        "        optD.step()\n",
        "        return D_loss.item()\n",
        "\n",
        "\n",
        "\n",
        "    def train_BD(self):\n",
        "\n",
        "        self.optimizerBD.zero_grad()\n",
        "\n",
        "        # make prediction on pairs \n",
        "        pred_enc_z, pred_enc_b, pred_enc_p, pred_enc_c = self.BD(  self.real_img, self.fake_z.detach(), self.fake_b.detach(), self.fake_p.detach(), self.fake_c.detach() )\n",
        "        pred_gen_z, pred_gen_b, pred_gen_p, pred_gen_c = self.BD(  self.fake_imgs[2].detach(), self.real_z, self.real_b, self.real_p, self.real_c )\n",
        "       \n",
        "        real_data = [ self.real_img, self.fake_z.detach(), self.fake_b.detach(), self.fake_p.detach(), self.fake_c.detach() ]\n",
        "        fake_data = [ self.fake_imgs[2].detach(), self.real_z, self.real_b, self.real_p, self.real_c ]\n",
        "        penalty = cal_gradient_penalty( self.BD, real_data, fake_data, device, type='mixed', constant=1.0)\n",
        "\n",
        "        D_loss =  -( pred_enc_z.mean()+pred_enc_b.mean()+pred_enc_p.mean()+pred_enc_c.mean()  ) + ( pred_gen_z.mean()+pred_gen_b.mean()+pred_gen_p.mean()+pred_gen_c.mean() ) + penalty*10\n",
        "        D_loss.backward()\n",
        "        self.optimizerBD.step()\n",
        "        return D_loss.item()\n",
        "      \n",
        "\n",
        "\n",
        "    def train_EG(self):\n",
        "\n",
        "        self.optimizerGE.zero_grad()\n",
        "\n",
        "        # reconstruct code and calculate loss \n",
        "        self.rec_p, _ = self.netsD[1]( self.fg_mk[0])\n",
        "        self.rec_c, _ = self.netsD[2]( self.fg_mk[1])\n",
        "        p_code_loss = self.CE( self.rec_p , self.real_p )\n",
        "        c_code_loss = self.CE( self.rec_c,  self.real_c )\n",
        "\n",
        "        # pred code and calculate loss (here no code constrain)\n",
        "        free_z, free_b, free_p, free_c = self.prepare_code()\n",
        "        with torch.no_grad():\n",
        "            free_fake_imgs, _, _, _ = self.netG( free_z, free_c, free_p, free_b, 'code'  )                   \n",
        "        pred_z, pred_b, pred_p, pred_c = self.encoder( free_fake_imgs[2].detach(),   'logits' )\n",
        "        z_pred_loss = self.L1( pred_z , free_z )\n",
        "        b_pred_loss = self.CE( pred_b , free_b )\n",
        "        p_pred_loss = self.CE( pred_p , free_p )\n",
        "        c_pred_loss = self.CE( pred_c,  free_c )        \n",
        "    \n",
        "    \n",
        "        # aux and backgroud real/fake loss\n",
        "        self.bg_class_pred, self.bg_rf_pred = self.netsD[0]( self.fake_imgs[0] ) \n",
        "        bg_rf_loss = self.RF_loss( self.bg_rf_pred, torch.ones_like( self.bg_rf_pred ) )*cfg.TRAIN.BG_LOSS_WT\n",
        "        bg_class_loss = self.RF_loss( self.bg_class_pred, torch.ones_like( self.bg_class_pred ) )\n",
        "\n",
        "        # child image real/fake loss  \n",
        "        _, self.child_rf_pred = self.netsD[2]( self.fake_imgs[-1] )\n",
        "        child_rf_loss = self.RF_loss( self.child_rf_pred, torch.ones_like(self.child_rf_pred) )\n",
        "  \n",
        "        # fool BD loss\n",
        "        pred_enc_z, pred_enc_b, pred_enc_p, pred_enc_c = self.BD(  self.real_img, self.fake_z, self.fake_b, self.fake_p, self.fake_c )\n",
        "        pred_gen_z, pred_gen_b, pred_gen_p, pred_gen_c = self.BD(  self.fake_imgs[2], self.real_z, self.real_b, self.real_p, self.real_c )\n",
        "        fool_BD_loss = ( pred_enc_z.mean()+pred_enc_b.mean()+pred_enc_p.mean()+pred_enc_c.mean()  ) - ( pred_gen_z.mean()+pred_gen_b.mean()+pred_gen_p.mean()+pred_gen_c.mean() ) \n",
        "             \n",
        "        EG_loss =  (p_code_loss+c_code_loss) + (bg_rf_loss+bg_class_loss) + child_rf_loss + fool_BD_loss + (5*z_pred_loss+5*b_pred_loss+10*p_pred_loss+10*c_pred_loss)\n",
        "        EG_loss.backward()\n",
        "\n",
        "        #print(\"EG LOSS\", EG_loss)\n",
        "\n",
        "\n",
        "        tmp_dict = {\"z_pred_loss\" : z_pred_loss.item(), \"b_pred_loss\" : b_pred_loss.item(), \"p_pred_loss\": p_pred_loss.item(),\n",
        "                    \"c_pred_loss\": c_pred_loss.item(), \"bg_rf_loss\": bg_rf_loss.item(), \"bg_class_loss\": bg_class_loss.item(),\n",
        "                    \"child_rf_loss\": child_rf_loss.item(), \"fool_BD_loss\": fool_BD_loss.item(), \"EG_loss\": EG_loss.item()}\n",
        "\n",
        "        return tmp_dict\n",
        "\n",
        "        self.optimizerGE.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        # prepare net, optimizer and loss\n",
        "        self.netG, self.netsD, self.BD, self.encoder = load_network_from_file()\n",
        "        self.optimizersD, self.optimizerBD, self.optimizerGE = define_optimizers( self.netG, self.netsD, self.BD, self.encoder )\n",
        "        self.RF_loss_un = nn.BCELoss(reduction='none')\n",
        "        self.RF_loss = nn.BCELoss()   \n",
        "        self.CE = CrossEntropy()        \n",
        "        self.L1 = nn.L1Loss()\n",
        "    \n",
        "\n",
        "\n",
        "        # get init avg_G (the param in avg_G is what we want)\n",
        "        avg_param_G = copy_G_params(self.netG) \n",
        "\n",
        "        max_counter = len(self.dataloader)\n",
        "        for epoch in range(cfg.TRAIN.FIRST_MAX_EPOCH):              \n",
        "\n",
        "            print(\"start epoch \",str(epoch))\n",
        "            #if torch.cuda.is_available():\n",
        "            count_data = 1\n",
        "            for data in self.dataloader:  \n",
        "                # prepare data              \n",
        "                self.real_img126, self.real_img, self.real_z, self.real_b, self.real_p, self.real_c, self.warped_bbox = self.prepare_data(data)\n",
        "\n",
        "                # forward for both E and G\n",
        "                self.fake_z, self.fake_b, self.fake_p, self.fake_c = self.encoder( self.real_img, 'softmax' )              \n",
        "                self.fake_imgs, self.fg_imgs, self.mk_imgs, self.fg_mk = self.netG( self.real_z, self.real_c, self.real_p, self.real_b, 'code'  )\n",
        "                                \n",
        "                # Update Discriminator networks in FineGAN      \n",
        "                d0_loss = self.train_Dnet(0)\n",
        "                d2_loss = self.train_Dnet(2)\n",
        "\n",
        "                # Update Bi Discriminator\n",
        "                bd_loss = self.train_BD()\n",
        "\n",
        "                # Update Encoder and G network\n",
        "                eg_loss_dict = self.train_EG()\n",
        "                for avg_p, p in zip( avg_param_G, self.netG.parameters() ):\n",
        "                    avg_p.mul_(0.999).add_(0.001, p.data)\n",
        "                \n",
        "                if( count_data == max_counter ):    \n",
        "                    print(\"end data number\" ,count_data)\n",
        "                    eg_loss_dict[\"d0_loss\"] = d0_loss\n",
        "                    eg_loss_dict[\"d2_loss\"] = d2_loss\n",
        "                    eg_loss_dict[\"bd_loss\"] = bd_loss\n",
        "                    eg_loss_dict[\"epoch\"] = epoch\n",
        "                    eg_loss_dict[\"data_number\"] = count_data\n",
        "\n",
        "                    log_loss(self.output_csv_file, eg_loss_dict, epoch)\n",
        "                    \n",
        "                if( count_data == max_counter % 25 == 0 ):\n",
        "                  print(\"end data number\" ,count_data)\n",
        "                count_data +=1\n",
        "\n",
        "            # Save model&image for each epoch  \n",
        "            backup_para = copy_G_params(self.netG)   \n",
        "            load_params(self.netG, avg_param_G)\n",
        "            self.encoder.eval()   \n",
        "            self.netG.eval()    \n",
        "            with torch.no_grad():   \n",
        "                self.code_z, self.code_b, self.code_p, self.code_c = self.encoder( self.fixed_image,'softmax')   \n",
        "                self.fake_imgs, self.fg_imgs, self.mk_imgs, self.fg_mk = self.netG(self.code_z, self.code_c, self.code_p, self.code_b, 'code')  \n",
        "                save_img_results(None, (self.fake_imgs+self.fg_imgs+self.mk_imgs+self.fg_mk), 0, self.image_dir)\n",
        "            self.encoder.train() \n",
        "            self.netG.train()            \n",
        "        \n",
        "\n",
        "            backup_para = copy_G_params(self.netG)   \n",
        "            load_params(self.netG, avg_param_G)\n",
        "            save_model( self.encoder, self.netG, self.netsD[0], self.netsD[1], self.netsD[2], self.BD, 0, self.model_dir )\n",
        "            save_opt(  self.optimizerGE,  self.optimizersD[0], self.optimizersD[2], self.optimizerBD,  0, self.opt_dir )\n",
        "            load_params(self.netG, backup_para)        \n",
        "\n",
        "            print( str(epoch)+'th epoch finished' )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \n",
        "    \n",
        "    manualSeed = random.randint(1, 10000)\n",
        "    random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "\n",
        "\n",
        "\n",
        "    # prepare output folder for this running and save all files \n",
        "    output_dir = make_output_dir()\n",
        "    shutil.copy2( sys.argv[0], output_dir)\n",
        "    shutil.copy2( 'model_train.py', output_dir)\n",
        "    shutil.copy2( 'config.py', output_dir)\n",
        "    shutil.copy2( 'utils.py', output_dir)\n",
        "    shutil.copy2( 'datasets.py', output_dir)\n",
        "\n",
        "    \n",
        "    trainer = Trainer(output_dir)   \n",
        "    print('start training now')\n",
        "    trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuMfO-YX0a1X"
      },
      "source": [
        "# Second Train"
      ]
    }
  ]
}